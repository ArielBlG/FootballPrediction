{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.impute import KNNImputer\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "import math\n",
    "import statistics\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest,chi2,mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to SQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_path = \"/Users/ariel-pc/Documents/שנה ג/SemesterB/Into to final project/Assignment3/database.sqlite\" # PATH to the DB\n",
    "con = sqlite3.connect(sql_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_query = \"\"\"\n",
    "select t.team_api_id team_id, t.team_long_name team, atr.date, atr.buildUpPlaySpeed,\n",
    "       atr.buildUpPlayDribbling, atr.buildUpPlayDribblingClass, atr.buildUpPlayPassing, \n",
    "       atr.buildUpPlayPositioningClass, atr.chanceCreationPassing,  atr.chanceCreationCrossing,\n",
    "        atr.chanceCreationShooting, \n",
    "       atr.chanceCreationPositioningClass, atr.defencePressure, atr.defenceAggression,\n",
    "       atr.defenceTeamWidth,  atr.defenceDefenderLineClass\n",
    "from team t join team_attributes atr on t.team_api_id = atr.team_api_id\n",
    "\"\"\"\n",
    "\n",
    "players_query = \"\"\"\n",
    "select pl.player_api_id player_id, pl.player_name player, pl.birthday, pl.height, pl.weight, pla.date, pla.overall_rating, \n",
    "       pla.potential, pla.preferred_foot, pla.attacking_work_rate, pla.defensive_work_rate, pla.crossing, pla.finishing,\n",
    "       pla.heading_accuracy, pla.short_passing, pla.volleys, pla.dribbling, pla.curve, pla.free_kick_accuracy,\n",
    "       pla.long_passing, pla.ball_control, pla.acceleration, pla.sprint_speed, pla.agility, pla.reactions, pla.balance,\n",
    "       pla.shot_power, pla.jumping, pla.stamina, pla.strength, pla.long_shots, pla.aggression, pla.interceptions,\n",
    "       pla.positioning, pla.vision, pla.penalties, pla.marking, pla.standing_tackle, pla.sliding_tackle, pla.gk_diving,\n",
    "       pla.gk_handling, pla.gk_kicking, pla.gk_positioning, pla.gk_reflexes\n",
    "from player pl join player_attributes pla on pl.player_api_id = pla.player_api_id\n",
    "\"\"\"\n",
    "\n",
    "match_query = \"\"\"\n",
    "select m.match_api_id match_id,\n",
    "c.name country, l.name league, m.season, m.stage, m.date, home.team_long_name home_team,\n",
    "       away.team_long_name away_team, m.home_team_goal home_goal, m.away_team_goal away_goal, m.goal\n",
    "from match m, country c, league l, team home, team away\n",
    "where m.country_id = c.id and m.league_id = l.id and\n",
    "      home.team_api_id = m.home_team_api_id and away.team_api_id = m.away_team_api_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.read_sql_query(teams_query, con)\n",
    "match = pd.read_sql_query(match_query, con)\n",
    "players = pd.read_sql_query(players_query, con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the teams DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_cp = teams.copy()\n",
    "teams_cp.info()\n",
    "teams.defenceDefenderLineClass.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummies for positioning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_w_dummies = pd.get_dummies(teams, columns=['chanceCreationPositioningClass'\n",
    "                                                 ,'buildUpPlayPositioningClass',\n",
    "                                                 'defenceDefenderLineClass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rearrange Team DataFrame for merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_w_dummies.date.unique()\n",
    "conditions = [(teams_w_dummies['date'] == '2010-02-22 00:00:00'), \n",
    "              (teams_w_dummies['date'] == '2011-02-22 00:00:00'), \n",
    "              (teams_w_dummies['date'] == '2012-02-22 00:00:00'), \n",
    "              (teams_w_dummies['date'] == '2013-09-20 00:00:00'), \n",
    "              (teams_w_dummies['date'] == '2014-09-19 00:00:00'), \n",
    "              (teams_w_dummies['date'] == '2015-09-10 00:00:00'), \n",
    "             ]\n",
    "choices = [\n",
    "            '2009/2010',\n",
    "            '2010/2011',\n",
    "            '2011/2012',\n",
    "            '2012/2013',\n",
    "            '2013/2014',\n",
    "            '2014/2015']\n",
    "teams_w_dummies['season'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature fill null attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_mean =  teams_w_dummies.groupby('buildUpPlayDribblingClass')['buildUpPlayDribbling'].mean()\n",
    "break_points = [group_by_mean[0], group_by_mean[2], group_by_mean[1]]\n",
    "buildUpPlayDribbling_list = []\n",
    "for i, _class in enumerate(teams_w_dummies.buildUpPlayDribblingClass):\n",
    "    try:\n",
    "        if not np.isnan(teams_w_dummies.buildUpPlayDribbling[i]):\n",
    "            buildUpPlayDribbling_list.append(teams_w_dummies.buildUpPlayDribbling[i])\n",
    "        elif _class == 'Little' and np.isnan(teams_w_dummies.buildUpPlayDribbling[i]):\n",
    "            buildUpPlayDribbling_list.append(break_points[0])\n",
    "        elif _class == 'Normal' and np.isnan(teams_w_dummies.buildUpPlayDribbling[i]):\n",
    "            buildUpPlayDribbling_list.append(break_points[1])\n",
    "        elif _class == 'Lots' and np.isnan(teams_w_dummies.buildUpPlayDribbling[i]):\n",
    "            buildUpPlayDribbling_list.append(break_points[2])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "teams_w_dummies['buildUpPlayDribbling'] = buildUpPlayDribbling_list\n",
    "teams_w_dummies = teams_w_dummies.drop_duplicates()\n",
    "del teams_w_dummies['buildUpPlayDribblingClass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_w_dummies.date = pd.to_datetime(teams_w_dummies.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df = teams_w_dummies[['team_id', 'team','season', 'date', 'buildUpPlaySpeed', 'buildUpPlayDribbling',\n",
    "       'buildUpPlayPassing', 'chanceCreationPassing', 'chanceCreationCrossing',\n",
    "       'chanceCreationShooting', 'defencePressure', 'defenceAggression',\n",
    "       'defenceTeamWidth', 'chanceCreationPositioningClass_Free Form',\n",
    "       'chanceCreationPositioningClass_Organised',\n",
    "       'buildUpPlayPositioningClass_Free Form',\n",
    "       'buildUpPlayPositioningClass_Organised',\n",
    "       'defenceDefenderLineClass_Cover',\n",
    "       'defenceDefenderLineClass_Offside Trap']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_list = set(['2008/2009', '2009/2010', '2010/2011', '2011/2012', \n",
    "                   '2012/2013','2013/2014', '2014/2015', '2015/2016'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate team average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df['team_avg_score'] = teams_df.loc[:,'buildUpPlaySpeed':'defenceTeamWidth'].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_copy = match.copy()\n",
    "match_copy.date = pd.to_datetime(match_copy.date)\n",
    "match_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get victories and losses for each team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df = match_copy.loc[:, ['league', 'season', 'home_team', 'away_team','home_goal', 'away_goal']]                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masks for lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_win = points_df.home_goal > points_df.away_goal\n",
    "away_win = points_df.home_goal < points_df.away_goal\n",
    "home_lose = points_df.home_goal < points_df.away_goal\n",
    "tie = points_df.home_goal == points_df.away_goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag 1 as win, 0 as lose, -1 as tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df['tag'] = np.select([home_win, tie], [1, 0], 2) # Multi label Classification\n",
    "# points_df['tag'] = np.select([home_win, tie], [1, 0], 0) # Binary Classification\n",
    "\n",
    "points_df['home_win'] = np.select([home_win], [1], 0)\n",
    "points_df['away_win'] = np.select([away_win], [1], 0)\n",
    "points_df['points_in_match'] = np.select([home_win,tie],[3,1],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_copy['home_win'] = points_df['home_win']\n",
    "match_copy['away_win'] = points_df['away_win']\n",
    "match_copy['points_in_match'] = points_df['points_in_match']\n",
    "match_copy['tag'] = points_df['tag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate cumulative away and home wins till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_copy['cum_home_wins'] = match_copy.groupby(['home_team'])['home_win'].cumsum().sub(match_copy.home_win)\n",
    "match_copy['cum_away_wins'] = match_copy.groupby(['away_team'])['away_win'].cumsum().sub(match_copy.away_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_copy['ones'] = 1\n",
    "match_copy['num_games_home'] = match_copy.groupby(['home_team'])['ones'].cumsum()\n",
    "match_copy['num_games_away'] = match_copy.groupby(['away_team'])['ones'].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate number of games in season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_season = match_copy[['date','season', 'home_team', 'ones']].set_index(['season','home_team','ones'])\n",
    "temp_season = temp_season.stack().reset_index(name='both')\n",
    "temp_season['new'] = temp_season.groupby(['season','home_team'])['ones'].cumsum()\n",
    "match_copy['num_games_home_season'] = temp_season['new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_season = match_copy[['date','season', 'away_team', 'ones']].set_index(['season','away_team','ones'])\n",
    "temp_season = temp_season.stack().reset_index(name='both')\n",
    "temp_season['new'] = temp_season.groupby(['season','away_team'])['ones'].cumsum()\n",
    "match_copy['num_games_away_season'] = temp_season['new']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate cumulative away and home wins in season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_season = match_copy[['date','season', 'home_team', 'home_win']].set_index(['season','home_team','home_win'])\n",
    "temp_season = temp_season.stack().reset_index(name='both')\n",
    "temp_season['new'] = temp_season.groupby(['season','home_team'])['home_win'].cumsum().sub(temp_season.home_win)\n",
    "match_copy['cum_home_win_season'] = temp_season['new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_season = match_copy[['date','season', 'away_team', 'away_win']].set_index(['season','away_team','away_win'])\n",
    "temp_season = temp_season.stack().reset_index(name='both')\n",
    "temp_season['new'] = temp_season.groupby(['season','away_team'])['away_win'].cumsum().sub(temp_season.away_win)\n",
    "match_copy['cum_away_win_season'] = temp_season['new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = match_copy.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate cumulative home and away goals in season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_season = match_df[['season', 'date', 'home_team', 'home_goal']].set_index(['season','home_team','home_goal'])\n",
    "temp_season = temp_season.stack().reset_index(name='both')\n",
    "temp_season['new'] = temp_season.groupby(['season','home_team'])['home_goal'].cumsum().sub(temp_season.home_goal)\n",
    "match_df['cum_home_goal_season'] = temp_season['new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_season = match_df[['season', 'date', 'away_team', 'away_goal']].set_index(['season','away_team','away_goal'])\n",
    "temp_season = temp_season.stack().reset_index(name='both')\n",
    "temp_season['new'] = temp_season.groupby(['season','away_team'])['away_goal'].cumsum().sub(temp_season.away_goal)\n",
    "match_df['cum_away_goal_season'] = temp_season['new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df_copy = match_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous meetings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_season = match_df_copy[['date', 'home_team','away_team','home_win']].set_index(['date','home_team','away_team'])\n",
    "temp_season = temp_season.stack().reset_index(name='both')\n",
    "temp_season['new'] = temp_season.groupby(['home_team','away_team'])['both'].cumsum().sub(temp_season.both)\n",
    "match_df_copy['cum_prev_meeting_home'] = temp_season['new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_season = match_df_copy[['date', 'home_team','away_team','away_win']].set_index(['date','home_team','away_team'])\n",
    "temp_season = temp_season.stack().reset_index(name='both')\n",
    "temp_season['new'] = temp_season.groupby(['home_team','away_team'])['both'].cumsum().sub(temp_season.both)\n",
    "match_df_copy['cum_prev_meeting_away'] = temp_season['new']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df_copy['total_h_wins_games_portion'] = match_df_copy['cum_home_wins'] / match_df_copy['num_games_home']\n",
    "match_df_copy['total_a_wins_games_portion'] = match_df_copy['cum_away_wins'] / match_df_copy['num_games_away']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df_copy['total_h_wins_portions_season'] = match_df_copy['cum_home_win_season'] / match_df_copy['num_games_home_season']\n",
    "match_df_copy['total_a_wins_portions_season'] = match_df_copy['cum_away_win_season'] / match_df_copy['num_games_away_season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df_copy['total_h_goals_portion'] = match_df_copy['cum_home_goal_season'] / match_df_copy['num_games_home_season']\n",
    "match_df_copy['total_a_goals_portion'] = match_df_copy['cum_away_goal_season'] / match_df_copy['num_games_away_season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df_copy['sub_win_portion_teams'] = match_df_copy['cum_home_goal_season'] - match_df_copy['cum_away_goal_season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df_copy['win_portion'] = match_df_copy['cum_home_wins'] / match_df_copy['cum_away_wins']\n",
    "match_df_copy['win_portion_season'] = match_df_copy['cum_home_win_season'] / match_df_copy['cum_away_win_season']\n",
    "match_df_copy['goal_portion'] = match_df_copy['cum_home_goal_season'] / match_df_copy['cum_away_goal_season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = match_df_copy[['match_id', 'country', 'league', 'season', 'stage', 'date', 'home_team',\n",
    "       'away_team', 'home_goal', 'away_goal', 'home_win', 'away_win',\n",
    "       'points_in_match',  'cum_home_wins', 'cum_away_wins', 'cum_home_win_season', 'cum_away_win_season',\n",
    "       'cum_home_goal_season', 'cum_away_goal_season', 'cum_prev_meeting_home',\n",
    "       'cum_prev_meeting_away', 'total_h_wins_games_portion',\n",
    "       'total_a_wins_games_portion', 'total_h_wins_portions_season',\n",
    "       'total_a_wins_portions_season', 'total_h_goals_portion',\n",
    "       'total_a_goals_portion', 'sub_win_portion_teams','tag']]\n",
    "temp_match_df = match_df.copy()\n",
    "temp_match_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Matches and Teams table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "season_list = ['2008/2009', '2009/2010', '2010/2011', '2011/2012', \n",
    "                   '2012/2013','2013/2014', '2014/2015', '2015/2016']\n",
    "idx_dict = {}\n",
    "for index in range(0,len(season_list)):\n",
    "    idx_dict[season_list[index]] = index\n",
    "\n",
    "temp_match_df = match_df.copy()\n",
    "temp_match_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix teams dataframe with missing season values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_set = set(['2008/2009', '2009/2010', '2010/2011', '2011/2012', \n",
    "                   '2012/2013','2013/2014', '2014/2015', '2015/2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seasons_to_add(season):\n",
    "    for i in range(0, season):\n",
    "        yield season_list[i]\n",
    "def find_seasons(df):\n",
    "    temp_dict = df.set_index('season').T.to_dict()\n",
    "    new_df = {}\n",
    "    keys_set = sorted(temp_dict.keys(), reverse=False)\n",
    "    missing_seasons = sorted(season_set - set(temp_dict.keys()), reverse=False)\n",
    "    first_index = idx_dict[keys_set[0]]\n",
    "    # Handle '2008/2009' -> key_set[0]\n",
    "    for test in get_seasons_to_add(first_index):\n",
    "        temp_dict[test] = temp_dict[keys_set[0]]\n",
    "        \n",
    "    # Handle rest of missing values\n",
    "    for i in range(1, len(missing_seasons)):\n",
    "        temp_dict[missing_seasons[i]] = temp_dict[missing_seasons[i-1]]\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_list = teams_df.team.unique()\n",
    "new_team_df = pd.DataFrame(columns=teams_df.columns)\n",
    "for team_name in tqdm.tqdm(teams_list):\n",
    "    df_to_concat = find_seasons(teams_df[teams_df['team'] == team_name])\n",
    "    df_to_concat = pd.DataFrame(df_to_concat).T.reset_index()\n",
    "    df_to_concat = df_to_concat.rename(columns = {'index':'season'})\n",
    "    new_team_df = pd.concat([new_team_df, df_to_concat], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_team_df = new_team_df.sort_values(['team','season'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Match table with Team table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "england_league = temp_match_df[match_df[\"league\"]==\"England Premier League\"]\n",
    "cols_to_add = list(new_team_df.columns[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cols_home(df1, df2,string):\n",
    "    for col in cols_to_add:\n",
    "        df1[col+'_'+string] = df2[col]\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_add = ['buildUpPlaySpeed',\n",
    "       'buildUpPlayDribbling', 'buildUpPlayPassing', 'chanceCreationPassing',\n",
    "       'chanceCreationCrossing', 'chanceCreationShooting', 'defencePressure',\n",
    "       'defenceAggression', 'defenceTeamWidth',\n",
    "       'chanceCreationPositioningClass_Free_Form',\n",
    "       'chanceCreationPositioningClass_Organised',\n",
    "       'buildUpPlayPositioningClass_Free_Form',\n",
    "       'buildUpPlayPositioningClass_Organised',\n",
    "       'defenceDefenderLineClass_Cover',\n",
    "       'defenceDefenderLineClass_Offside_Trap','team_avg_score']\n",
    "new_list_to_add_home = [col + '_home' for col in cols_to_add]\n",
    "home_dict = dict(zip(cols_to_add,new_list_to_add_home))\n",
    "\n",
    "new_list_to_add_away = [col + '_away' for col in cols_to_add]\n",
    "away_dict = dict(zip(cols_to_add, new_list_to_add_away))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = temp_match_df.merge(new_team_df, left_on=['home_team','season'], right_on=['team','season'],suffixes=('_home','_home'))\n",
    "df = df.drop(columns =['team_id', 'team','date_home'])\n",
    "df = df.rename(columns = home_dict)\n",
    "\n",
    "df = df.merge(new_team_df, left_on=['away_team','season'], right_on=['team','season'],suffixes=('_away','_away'))\n",
    "df = df.rename(columns = away_dict)\n",
    "df = df.drop(columns=['chanceCreationPositioningClass_Free Form_away',\n",
    "                      'defenceDefenderLineClass_Offside Trap_away',\n",
    "                     'buildUpPlayPositioningClass_Free Form_away'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unneseccary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['country','league','stage','home_team','away_team','home_goal','away_goal','home_win','away_win','points_in_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "col_list = ['match_id','season', 'cum_home_wins', 'cum_away_wins', 'cum_home_win_season',\n",
    "       'cum_away_win_season', 'cum_home_goal_season', 'cum_away_goal_season',\n",
    "       'cum_prev_meeting_home', 'cum_prev_meeting_away',\n",
    "       'total_h_wins_games_portion', 'total_a_wins_games_portion',\n",
    "       'total_h_wins_portions_season', 'total_a_wins_portions_season',\n",
    "       'total_h_goals_portion', 'total_a_goals_portion',\n",
    "       'sub_win_portion_teams',  'team_avg_score_home','buildUpPlaySpeed_home',\n",
    "       'buildUpPlayDribbling_home', 'buildUpPlayPassing_home',\n",
    "       'chanceCreationPassing_home', 'chanceCreationCrossing_home',\n",
    "       'chanceCreationShooting_home', 'defencePressure_home',\n",
    "       'defenceAggression_home', 'defenceTeamWidth_home',\n",
    "       'chanceCreationPositioningClass_Organised_home',\n",
    "       'buildUpPlayPositioningClass_Organised_home',\n",
    "       'defenceDefenderLineClass_Cover_home', 'team_id', 'team', 'date','team_avg_score_away',\n",
    "       'buildUpPlaySpeed_away', 'buildUpPlayDribbling_away',\n",
    "       'buildUpPlayPassing_away', 'chanceCreationPassing_away',\n",
    "       'chanceCreationCrossing_away', 'chanceCreationShooting_away',\n",
    "       'defencePressure_away', 'defenceAggression_away',\n",
    "       'defenceTeamWidth_away',\n",
    "       'chanceCreationPositioningClass_Organised_away',\n",
    "       'buildUpPlayPositioningClass_Organised_away',\n",
    "       'defenceDefenderLineClass_Cover_away','tag']\n",
    "\n",
    "df = df[col_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocces and prepare integration of players features to final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(sql_path)\n",
    "match_query = \"\"\"\n",
    "select m.match_api_id match_id,\n",
    "m.home_player_1 home_pla_1, m.home_player_2 home_pla_2, m.home_player_3 home_pla_3, m.home_player_4 home_pla_4, m.home_player_5 home_pla_5,\n",
    "m.home_player_6 home_pla_6, m.home_player_7 home_pla_7, m.home_player_8 home_pla_8, m.home_player_9 home_pla_9, m.home_player_10 home_pla_10,m.home_player_11 home_pla_11,  \n",
    "m.away_player_1 away_pla_1, m.away_player_2 away_pla_2, m.away_player_3 away_pla_3, m.away_player_4 away_pla_4, m.away_player_5 away_pla_5,\n",
    "m.away_player_6 away_pla_6, m.away_player_7 away_pla_7, m.away_player_8 away_pla_8, m.away_player_9 away_pla_9, m.away_player_10 away_pla_10,m.away_player_11 away_pla_11\n",
    "from match m\n",
    "\"\"\"\n",
    "match_temp_naor = pd.read_sql_query(match_query, con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Matchs with NaN player id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_temp_naor=match_temp_naor.dropna(how='any',axis=0)\n",
    "match_temp_naor.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Players DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "players = players.drop_duplicates()\n",
    "players_cp=players.copy()\n",
    "sum_of_NaN_values=players.isnull().sum()\n",
    "is_NaN = players. isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "# row_has_NaN\n",
    "rows_with_NaN = players[row_has_NaN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's brake down the problem to suspicious Nan accurances: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# group 835:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, lets investigate all the attributes that are with 835 Nan values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets try and take the cleaning aprouch by the repeating numbers in the rows which contain none\n",
    "#maybe those are certain players that needs to be removed(almost empty records).\n",
    "attr_with_NaN_835=['player_id', 'player']\n",
    "for row in sum_of_NaN_values.iteritems():\n",
    "    if row[1]==835:\n",
    "        attr_with_NaN_835.append(row[0])\n",
    "# print(attr_with_NaN_835)\n",
    "players_only_835_attr =  rows_with_NaN[attr_with_NaN_835]\n",
    "rows_835_with_NaN=players_only_835_attr[(players_only_835_attr.isnull()).any(axis=1)]\n",
    "print(len(rows_835_with_NaN))\n",
    "rows_835_with_NaN.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as suspected, there is correlation between all these NaN values, they all are part of empty\n",
    "records of players(lack of data).\n",
    "we can deal with this group of NaN values by removing the records of the players involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get player_id for each record we want to remove\n",
    "player_indexs_to_remove=rows_835_with_NaN.index\n",
    "players_cp.drop(player_indexs_to_remove, inplace=True)\n",
    "players_cp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see, there are 835 less records in the players data frame.\n",
    "now, lets take a look at the NaN values again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_NaN_values=players_cp.isnull().sum()\n",
    "print(sum_of_NaN_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# group 1877:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "again, lets investigate all the attributes that are with 1877 Nan values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the rows with Nan left to handle\n",
    "rows_with_NaN= players_cp[players_cp.isnull().any(axis=1)]\n",
    "attr_with_NaN_1877=['player_id', 'player']\n",
    "\n",
    "for row in sum_of_NaN_values.iteritems():\n",
    "    if row[1]==1877:\n",
    "        attr_with_NaN_1877.append(row[0])\n",
    "\n",
    "players_only_1877_attr =  rows_with_NaN[attr_with_NaN_1877]\n",
    "# players_only_1877_attr\n",
    "rows_1877_with_NaN=players_only_1877_attr[(players_only_1877_attr.isnull()).any(axis=1)]\n",
    "print(len(rows_1877_with_NaN))\n",
    "rows_1877_with_NaN.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks as if its the same case like group 835  only that this time it's player related. \n",
    "can be understood from the fact that the 835 group contained distinct records of players whilst here we have numerous records of some of the players.\n",
    "either way it will be dealt with likewise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get indexs for each record we want to remove\n",
    "player_indexs_to_remove=rows_1877_with_NaN.index\n",
    "players_cp.drop(player_indexs_to_remove, inplace=True)\n",
    "sum_of_NaN_values=players_cp.isnull().sum()\n",
    "print(sum_of_NaN_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# group attacking_work_rate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, lets take a look at the values of the problematic attribute, since its of object type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_cp.attacking_work_rate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "players_cp.attacking_work_rate.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at the distribution of this attribute we can assume that we can take the values: \"None\", \"le\", \"norm\", \"stoc\" and \"y\" and classify them as \"medium\".that classification should not damage the contribution of the attribute's values since the majority of the players are classified as \"medium\".\n",
    "now, we will make the attribute numeric, classifying:\n",
    "\"low\" as 1\n",
    "\"medium\" as 2\n",
    "and\n",
    "\"high\" as 3.\n",
    "the context is preserved because 1, 2 and 3 have the same mathematical relation as low, medium and high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacking_work_rate_list = []\n",
    "for i, _class in enumerate(players_cp.attacking_work_rate):\n",
    "    try:\n",
    "#         print(type(_class))\n",
    "        if _class == \"low\":\n",
    "            attacking_work_rate_list.append(1)\n",
    "        elif _class == \"high\":\n",
    "            attacking_work_rate_list.append(3)\n",
    "        else:\n",
    "            attacking_work_rate_list.append(2)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "players_cp['attacking_work_rate'] = attacking_work_rate_list\n",
    "players_cp = players_cp.drop_duplicates()\n",
    "players_cp.attacking_work_rate.value_counts()\n",
    "players_cp.attacking_work_rate.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_NaN_values=players_cp.isnull().sum()\n",
    "print(sum_of_NaN_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after proccesing the table to the point which there are no NaN values, it is needed to look at the non numeric value types and consider further actions in the preproccess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for attribute_column in players_cp:\n",
    "    if players_cp.dtypes[attribute_column] == np.object:\n",
    "        print(players_cp[attribute_column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# group defensive_work_rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "players_cp.defensive_work_rate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_cp.defensive_work_rate.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at the distribution of this attribute we can assume that we can take the values: \"ean\", \"es\", \"ormal\", \"_0\", \"tocky\" and \"0\" to \"9\" and classify them as \"medium\".that classification should not damage the contribution of the attribute's values since the majority of the players are classified as \"medium\".\n",
    "now, we will make the attribute numeric, classifying:\n",
    "\"low\" as 1\n",
    "\"medium\" as 2\n",
    "and\n",
    "\"high\" as 3.\n",
    "the context is preserved because 1, 2 and 3 have the same mathematical relation as low, medium and high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defensive_work_rate_list = []\n",
    "for i, _class in enumerate(players_cp.defensive_work_rate):\n",
    "    try:\n",
    "#         print(type(_class))\n",
    "        if _class == \"low\":\n",
    "            defensive_work_rate_list.append(1)\n",
    "        elif _class == \"high\":\n",
    "            defensive_work_rate_list.append(3)\n",
    "        else:\n",
    "            defensive_work_rate_list.append(2)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "players_cp['defensive_work_rate'] = defensive_work_rate_list\n",
    "players_cp = players_cp.drop_duplicates()\n",
    "players_cp.defensive_work_rate.value_counts()\n",
    "players_cp.defensive_work_rate.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preferred_foot  drop: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_cp.drop('preferred_foot',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute_column in players_cp:\n",
    "    if players_cp.dtypes[attribute_column] == np.object:\n",
    "        print(players_cp[attribute_column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating age feature:\n",
    "we want to add \"age\" feature to the player dataset after Considerat the contribution of the attribute's values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_cp['date_year'] = pd.to_datetime(players_cp['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "players_cp['birthday_year'] = pd.to_datetime(players_cp['birthday'], format='%Y-%m-%d %H:%M:%S')\n",
    "print (players_cp['date_year'])\n",
    "print (players_cp['birthday_year'])\n",
    "players_cp['date_year'] = players_cp.date_year.apply(lambda x: x.year)\n",
    "players_cp['birthday_year'] = players_cp.birthday_year.apply(lambda x: x.year)\n",
    "print (players_cp['date_year'])\n",
    "print (players_cp['birthday_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_cp['age']= players_cp['date_year'] - players_cp['birthday_year']\n",
    "print (players_cp[['date_year', 'birthday_year', 'age' ]])\n",
    "print (players_cp.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# birthday ,birthday_year and date_year drop:\n",
    "Now after we extract the age featue we will drop the birthday feature (in addition to birthday_year and date_year) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_cp.drop('birthday',axis=1,inplace=True)\n",
    "players_cp.drop('date_year',axis=1,inplace=True)\n",
    "players_cp.drop('birthday_year',axis=1,inplace=True)\n",
    "print (players_cp.dtypes)\n",
    "print (players_cp.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# player name drop:\n",
    "as we can see we left with 2 features from type object: date and player.\n",
    "we need the date to merge tables, but the player name feature gives no contribution so we have decided to drop it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_cp.drop('player',axis=1,inplace=True)\n",
    "players_cp[['player_id','date','overall_rating']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# players feature extraction + selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMI + Age: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_prime_age=26\n",
    "lbs_to_kgs_factor=0.45359237\n",
    "BMI_age_list=[]\n",
    "for idx,p in players_cp[['height','weight','age']].iterrows():\n",
    "    new_att = ((p.weight*lbs_to_kgs_factor)/(math.pow((p.height/100),2)))*((avg_prime_age/p.age)*0.5)\n",
    "    BMI_age_list.append(new_att)\n",
    "    \n",
    "players_cp['BMI_age_corelay']=BMI_age_list\n",
    "players_cp.drop(['height','weight'],axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unitary attributes combined to 1 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players_cp.columns\n",
    "list_of_relevant_attr=['crossing', 'finishing',\n",
    "       'heading_accuracy', 'short_passing', 'volleys', 'dribbling', 'curve',\n",
    "       'free_kick_accuracy', 'long_passing', 'ball_control', 'acceleration',\n",
    "       'sprint_speed', 'agility', 'reactions', 'balance', 'shot_power',\n",
    "       'jumping', 'stamina', 'strength', 'long_shots', 'aggression',\n",
    "       'interceptions', 'positioning', 'vision', 'penalties', 'marking',\n",
    "       'standing_tackle', 'sliding_tackle', 'gk_diving', 'gk_handling',\n",
    "       'gk_kicking', 'gk_positioning', 'gk_reflexes']\n",
    "\n",
    "list_of_comb_attr=[]\n",
    "\n",
    "num_of_attr = len(list_of_relevant_attr)\n",
    "for idx , p in players_cp[list_of_relevant_attr].iterrows():\n",
    "    sum_of_attr=0\n",
    "    rec_avg=0\n",
    "    for attr in p.values:\n",
    "        sum_of_attr+=attr\n",
    "    rec_avg=(sum_of_attr/num_of_attr)\n",
    "    list_of_comb_attr.append(rec_avg)\n",
    "\n",
    "players_cp['avg_attr_rating']=list_of_comb_attr\n",
    "players_cp.drop(list_of_relevant_attr,axis='columns', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit player statistics to the season format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_cp['date']=pd.to_datetime(players_cp['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "players_cp['date']=pd.DatetimeIndex(players_cp['date']).year\n",
    "players_cp.drop_duplicates(subset=['player_id','date'], inplace=True)\n",
    "season_to_year_dict = { '2006':'2006/2007','2007':'2007/2008','2008':'2008/2009', '2009':'2009/2010', '2010':'2010/2011', '2011':'2011/2012', \n",
    "                   '2012':'2012/2013','2013':'2013/2014', '2014':'2014/2015','2015':'2015/2016','2016':'2016/2017'}\n",
    "season_list = []\n",
    "for index, year in players_cp.date.iteritems():\n",
    "    season_list.append(season_to_year_dict[str(year)])\n",
    "players_cp['season']=season_list\n",
    "del players_cp['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge temp match table with players proccessed table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_num_list=['home_pla_1', 'home_pla_2', 'home_pla_3', 'home_pla_4','home_pla_5',\n",
    " 'home_pla_6',  'home_pla_7',  'home_pla_8', 'home_pla_9',  'home_pla_10', 'home_pla_11',  \n",
    " 'away_pla_1',  'away_pla_2',  'away_pla_3',  'away_pla_4',  'away_pla_5',\n",
    " 'away_pla_6',  'away_pla_7',  'away_pla_8', 'away_pla_9',  'away_pla_10', 'away_pla_11']\n",
    "p_num_extend=[]\n",
    "for p_num in p_num_list:\n",
    "    for col_name in players_cp.columns[1:]:\n",
    "        if col_name != 'season':\n",
    "            p_num_extend.append(p_num+'_'+col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill new players values with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_idle_fil_list=[np.NaN]*len(match_temp_naor['match_id'])\n",
    "for c in p_num_extend:\n",
    "    match_temp_naor[c]=NaN_idle_fil_list\n",
    "df=pd.merge(df,match_temp_naor, on='match_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill the values of the Match with the Players values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_season=players_cp['season']\n",
    "del players_cp['season']\n",
    "players_cp['season']=tmp_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_is_ok(season,df):\n",
    "    tmp = df.loc[df['season']==season]\n",
    "    if tmp.empty:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to_existing_season(season_missing,df):\n",
    "    season_to_year_list = ['2006/2007','2007/2008','2008/2009', '2009/2010','2010/2011', '2011/2012', \n",
    "                   '2012/2013','2013/2014','2014/2015','2015/2016','2016/2017']\n",
    "    \n",
    "    season_index = season_to_year_list.index(season_missing)\n",
    "    while season_index>0:\n",
    "        season_index-=1\n",
    "        if season_is_ok(season_to_year_list[season_index],df):\n",
    "            return season_to_year_list[season_index]\n",
    "    for i in range(0,len(season_to_year_list)):\n",
    "        if season_is_ok(season_to_year_list[i],df):\n",
    "            return season_to_year_list[i]\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx,match_tmp in df.iterrows():\n",
    "    for p_num,p_x in enumerate(p_num_list):\n",
    "        from_idx=69+(7*p_num)\n",
    "        to_idx= from_idx+7\n",
    "        try:\n",
    "            temp_var = players_cp.loc[(players_cp['season']==match_tmp['season'])&(players_cp['player_id']==match_tmp[p_x])]\n",
    "            if(temp_var.empty):\n",
    "                good_season=change_to_existing_season(match_tmp['season'], players_cp.loc[players_cp['player_id']==match_tmp[p_x]])\n",
    "                if good_season==False :\n",
    "                    temp_var = [-1]*7\n",
    "                else:\n",
    "                    temp_var = players_cp.loc[(players_cp['season']==good_season)&(players_cp['player_id']==match_tmp[p_x])].iloc[0,1:8]\n",
    "            else:\n",
    "                temp_var = temp_var.iloc[0,1:8]\n",
    "            data_to_add=list(temp_var)\n",
    "            df.iloc[idx,from_idx:(to_idx)]=data_to_add\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fill NaN values with mean of the positional player of all players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values={}\n",
    "for col in p_num_extend:\n",
    "    values[col] = df[col].mean()\n",
    "df.fillna(value=values,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_NaN_values=df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('/Users/aspir/Documents/studies/year3/proj_prep/ML/data_afterpreprocess_united.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team based feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[50]\n",
    "print(df.iloc[0,116:182:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_of_positional(l):\n",
    "    tmp_sfdgh=statistics.mean(l)\n",
    "    return tmp_sfdgh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the player portions by team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "counter = 2\n",
    "lst_home_overall = []\n",
    "lst_home = []\n",
    "lst_away_overall = []\n",
    "lst_away = []\n",
    "lst_home_avg_attr_rating = []\n",
    "lst_away_avg_attr_rating = []\n",
    "lst_home_def_rate = []\n",
    "lst_away_def_rate = []\n",
    "lst_home_att_rate = []\n",
    "lst_away_att_rate = []\n",
    "\n",
    "for index,row in tqdm.tqdm(df.iterrows()):\n",
    "    lst_home.append(statistics.mean(list(row.iloc[49:115:6])))\n",
    "    lst_home_overall.append(statistics.mean(list(row.iloc[48:114:6])))\n",
    "    lst_home_avg_attr_rating.append(statistics.mean(list(row.iloc[53:119:6])))\n",
    "    lst_home_def_rate.append(statistics.mean(list(row.iloc[51:117:6])))\n",
    "    lst_home_att_rate.append(statistics.mean(list(row.iloc[50:114:6])))\n",
    "    lst_away.append(statistics.mean(list(row.iloc[115:181:6])))\n",
    "    lst_away_overall.append(statistics.mean(list(row.iloc[114:180:6])))\n",
    "    lst_away_avg_attr_rating.append(statistics.mean(list(row.iloc[119:184:6])))\n",
    "    lst_away_def_rate.append(statistics.mean(list(row.iloc[117:182:6])))\n",
    "    lst_away_att_rate.append(statistics.mean(list(row.iloc[116:182:6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_potential_home'] = lst_home\n",
    "df['avg_potential_away'] = lst_away\n",
    "df['avg_overall_rating_home'] = lst_home_overall\n",
    "df['avg_overall_rating_away'] = lst_away_overall\n",
    "df['avg_attr_rating__home'] = lst_home_avg_attr_rating\n",
    "df['avg_attr_rating__away'] = lst_away_avg_attr_rating\n",
    "df['avg_def_rate_home'] = lst_home_def_rate\n",
    "df['avg_def_rate_away'] = lst_away_def_rate\n",
    "df['avg_att_rate_home'] = lst_home_att_rate\n",
    "df['avg_att_rate_away'] = lst_away_att_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('/Users/aspir/Documents/studies/year3/proj_prep/ML/data_afterpreprocess_united.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv('/Users/aspir/Documents/studies/year3/proj_prep/ML/data_afterpreprocess_united.csv')\n",
    "dataset = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,12):\n",
    "    del dataset['away_pla_'+str(i)+'_defensive_work_rate']\n",
    "    del dataset['home_pla_'+str(i)+'_defensive_work_rate']\n",
    "\n",
    "    del dataset['away_pla_'+str(i)+'_attacking_work_rate']\n",
    "    del dataset['home_pla_'+str(i)+'_attacking_work_rate']\n",
    "    \n",
    "    del dataset['home_pla_' +str(i)+'_BMI_age_corelay']\n",
    "    del dataset['away_pla_' +str(i)+'_BMI_age_corelay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset['Unnamed: 0']\n",
    "del dataset['Unnamed: 0.1']\n",
    "del dataset['match_id']\n",
    "del dataset['team']\n",
    "del dataset['date']\n",
    "del dataset['team_id']\n",
    "lst_to_del = ['defenceDefenderLineClass_Cover_home',\n",
    "             'defenceTeamWidth_away',\n",
    "             'defenceTeamWidth_home',\n",
    "             'defenceAggression_away',\n",
    "             'defenceAggression_home',\n",
    "             'chanceCreationPassing_away',\n",
    "             'chanceCreationPassing_home',\n",
    "             'chanceCreationCrossing_away',\n",
    "             'defenceDefenderLineClass_Cover_away',\n",
    "             'buildUpPlayDribbling_away',\n",
    "             'chanceCreationCrossing_home',\n",
    "             'buildUpPlaySpeed_home',\n",
    "             'buildUpPlaySpeed_away',\n",
    "             'buildUpPlayDribbling_home',\n",
    "             'chanceCreationShooting_away']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate portions of team statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns = lst_to_del)\n",
    "dataset['team_avg_portion'] = dataset['team_avg_score_home'] / dataset['team_avg_score_away']\n",
    "dataset['buildUpPlayPassing_portion'] = dataset['buildUpPlayPassing_home'] / dataset['buildUpPlayPassing_away']\n",
    "dataset['defencePressure_portion'] = dataset['defencePressure_home'] / dataset['defencePressure_away']\n",
    "dataset['win_portion'] = dataset['cum_home_wins'] / dataset['cum_away_wins']\n",
    "dataset['win_portion_season'] = dataset['cum_home_win_season'] / dataset['cum_away_win_season']\n",
    "dataset['goal_portion'] = dataset['cum_home_goal_season'] / dataset['cum_away_goal_season']\n",
    "dataset = dataset.replace(np.nan,0)\n",
    "dataset.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = dataset['tag']\n",
    "del dataset['tag']\n",
    "dataset['tag'] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unnessecary columns after feature extraction and re arrange columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset['team_avg_score_away']\n",
    "del dataset['team_avg_score_home']\n",
    "del dataset['team_avg_portion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split to train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset[dataset['season'] < '2015/2016']\n",
    "del train['season']\n",
    "test = dataset[dataset['season'] >= '2015/2016']\n",
    "del test['season']\n",
    "del dataset['season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train.iloc[:,:-1], train.iloc[:,-1:]\n",
    "x_test, y_test = test.iloc[:,:-1], test.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define scaler and fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(x_train)\n",
    "scaled_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = SelectKBest(chi2, k=2)\n",
    "fit = X_new.fit(scaled_train, y_train)\n",
    "\n",
    "features_scores = []\n",
    "list_features = list(dataset.columns)\n",
    "for idx in range(len(X_new.scores_)):\n",
    "    features_scores.append((list_features[idx],X_new.scores_[idx]))\n",
    "sorted_features = sorted(features_scores,key=lambda x: x[1],reverse=True)\n",
    "sorted_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for hyperparmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "xgb = xgb.XGBClassifier(learning_rate=0.02, n_estimators=600, objective='multi:softmax',\n",
    "                    silent=True, nthread=-1)\n",
    "grid = GridSearchCV(xgb, param_grid=params, scoring='accuracy', \n",
    "                                   n_jobs=4,  verbose=3)\n",
    "grid.fit(scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'colsample_bytree' : 0.5,\n",
    "    'max_depth': 7,  # the maximum depth of each tree\n",
    "    'min_child_weight' : 5,\n",
    "    '_estimators' : 100,\n",
    "    'subsample' : 0.5,\n",
    "    'objective': 'multi:softmax',  # error evaluation for multiclass training\n",
    "#     'objective': 'binary:logistic', # binary classifier\n",
    "    'num_class': 3\n",
    "    }  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations\n",
    "xgbmodel = xgb.XGBClassifier(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbmodel.fit(scaled_train, y_train)\n",
    "xgbmodel.score(scaled_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgbmodel.predict(scaled_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels = [2,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "input_size = 106\n",
    "output_size = 3\n",
    "# output_size = 2 # Binary Classifier\n",
    "hidden_layer_size = 100\n",
    "batch_size = 64\n",
    "max_epochs = 1000\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(input_size), \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='sigmoid'), \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='sigmoid'), \n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='sigmoid'), \n",
    "    tf.keras.layers.Dense(output_size, activation='softmax')])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "# create the model\n",
    "model.compile(optimizer=optimizer, loss='SparseCategoricalCrossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "# train the model\n",
    "model.fit(scaled_train, \n",
    "          np.array(y_train), \n",
    "          batch_size=batch_size, \n",
    "          epochs=max_epochs,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(scaled_test, np.array(y_test)),\n",
    "          verbose = 2) \n",
    "test_loss, test_accuracy = model.evaluate(scaled_test, np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(scaled_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for hyperparametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n",
    "                               n_iter = 100, cv = 3, verbose=3, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 2000,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 10,\n",
    " 'bootstrap': True}\n",
    "rf = RandomForestClassifier(n_estimators=2000,min_samples_split=5, min_samples_leaf=1, max_features='sqrt',\n",
    "                           max_depth=10, bootstrap=True)\n",
    "rf.fit(x_train, y_train.ravel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(scaled_test)\n",
    "print(metrics.classification_report(y_test,y_pred, labels=[0,1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    random_strength=0.1,\n",
    "    depth=8,\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='Accuracy',\n",
    "    leaf_estimation_method='Newton'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model.fit(scaled_train, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = catboost_model.predict(scaled_test)\n",
    "# print(\"F1 score\", metrics.f1_score(y_test,y_pred, average='micro'))\n",
    "print(metrics.classification_report(y_test,y_pred, labels=[0,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
